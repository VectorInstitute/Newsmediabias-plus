
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://vectorinstitute.github.io/Newsmediabias-plus/Benchmark.html">
      
      
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Benchmarking Annotation Framework - News Media Bias Plus</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#benchmarking-annotation-framework" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="News Media Bias Plus" class="md-header__button md-logo" aria-label="News Media Bias Plus" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            News Media Bias Plus
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Benchmarking Annotation Framework
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="News Media Bias Plus" class="md-nav__button md-logo" aria-label="News Media Bias Plus" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    News Media Bias Plus
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="dataset.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Datasets
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="HumaniBench.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HumaniBench
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="VLDBench.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VLDBench
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Fairsense.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fairsense
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Publications.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Publications
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="About-us.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About Us
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmarking-results-text-based-models" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmarking Results: Text-Based Models
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="benchmarking-annotation-framework">Benchmarking Annotation Framework</h1>
<h2 id="overview">Overview</h2>
<p>This page presents the performance benchmarking of Small Language Models (SLMs) and Large Language Models (LLMs) within our annotation framework. The objective is to evaluate how these models perform in tasks involving text and multimodal data (text + image). For this benchmarking, <strong>SLMs</strong> are defined as models with fewer parameters, typically below 15 million, such as BERT and GPT-2. In contrast, <strong>LLMs</strong>—including models like Llama3, Mistral, Gemma, and Phi—possess hundreds of millions to billions of parameters. This scale difference highlights the trade-off between efficiency and complexity when handling various tasks and datasets.</p>
<h2 id="benchmarking-results-text-based-models">Benchmarking Results: Text-Based Models</h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>Configuration</th>
<th>Precision</th>
<th>Recall</th>
<th>F1</th>
<th>Test Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Small Language Models</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BERT-base-uncased</td>
<td>FT</td>
<td>0.8887</td>
<td>0.8870</td>
<td>0.8878</td>
<td>0.8870</td>
</tr>
<tr>
<td>DistilBERT</td>
<td>FT</td>
<td>0.8665</td>
<td>0.8554</td>
<td>0.8609</td>
<td>0.8710</td>
</tr>
<tr>
<td>RoBERTa-base</td>
<td>FT</td>
<td>0.8940</td>
<td>0.8940</td>
<td>0.8940</td>
<td>0.8940</td>
</tr>
<tr>
<td>GPT2</td>
<td>FT</td>
<td>0.8762</td>
<td>0.8751</td>
<td>0.8756</td>
<td>0.8751</td>
</tr>
<tr>
<td>BART</td>
<td>FT</td>
<td>0.8762</td>
<td>0.8760</td>
<td>0.8761</td>
<td>0.8760</td>
</tr>
<tr>
<td><strong>Large Language Models</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Llama 3.1-8B-instruct</td>
<td>0-shot</td>
<td>0.8280</td>
<td>0.6890</td>
<td>0.7521</td>
<td>0.7200</td>
</tr>
<tr>
<td></td>
<td>5-shot</td>
<td>0.8400</td>
<td>0.7700</td>
<td>0.8035</td>
<td>0.7905</td>
</tr>
<tr>
<td></td>
<td>IFT</td>
<td>0.8019</td>
<td>0.8019</td>
<td>0.8019</td>
<td>0.8180</td>
</tr>
<tr>
<td>Llama 3.1-8B (base)</td>
<td>FT</td>
<td>0.8800</td>
<td>0.8600</td>
<td>0.8699</td>
<td>0.8320</td>
</tr>
<tr>
<td>Llama 3.2-3B-instruct</td>
<td>0-shot</td>
<td>0.7386</td>
<td>0.7550</td>
<td>0.7467</td>
<td>0.6897</td>
</tr>
<tr>
<td></td>
<td>5-shot</td>
<td>0.7989</td>
<td>0.6840</td>
<td>0.7370</td>
<td>0.6133</td>
</tr>
<tr>
<td></td>
<td>IFT</td>
<td>0.8390</td>
<td>0.7984</td>
<td>0.8182</td>
<td>0.8084</td>
</tr>
<tr>
<td>Llama 3.2-3B (base)</td>
<td>FT</td>
<td>0.8400</td>
<td>0.8500</td>
<td>0.8450</td>
<td>0.8200</td>
</tr>
<tr>
<td>Mistral-v0.3 7B-instruct</td>
<td>0-shot</td>
<td>0.8153</td>
<td>0.5250</td>
<td>0.6387</td>
<td>0.6990</td>
</tr>
<tr>
<td></td>
<td>5-shot</td>
<td>0.8319</td>
<td>0.8134</td>
<td>0.8225</td>
<td>0.7830</td>
</tr>
<tr>
<td></td>
<td>IFT</td>
<td>0.8890</td>
<td>0.9240</td>
<td>0.9062</td>
<td>0.7980</td>
</tr>
<tr>
<td>Mistral-v0.3 7B (base)</td>
<td>FT</td>
<td>0.8200</td>
<td>0.7400</td>
<td>0.7779</td>
<td>0.8014</td>
</tr>
<tr>
<td>Qwen2.5-7B</td>
<td>0-shot</td>
<td>0.8576</td>
<td>0.8576</td>
<td>0.8576</td>
<td>0.8576</td>
</tr>
<tr>
<td></td>
<td>5-shot</td>
<td>0.8660</td>
<td>0.8790</td>
<td>0.8724</td>
<td>0.8900</td>
</tr>
<tr>
<td></td>
<td>IFT</td>
<td>0.8357</td>
<td>0.8474</td>
<td>0.8415</td>
<td>0.8474</td>
</tr>
</tbody>
</table>
<p><strong>Table 1</strong>: Performance metrics for various language models and configurations. Configuration types: 0-shot = No prior examples used for inference, 5-shot = Five examples provided for context before inference, FT = Fine-tuned on task-specific data, IFT = Instruction fine-tuned with targeted training.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Config. (Text-Image)</th>
<th>Precision</th>
<th>Recall</th>
<th>F1</th>
<th>Test Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Small Language Models</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>SpotFake (XLNET + VGG-19)</td>
<td>FT</td>
<td>0.7415</td>
<td>0.6790</td>
<td>0.7089</td>
<td>0.8151</td>
</tr>
<tr>
<td>BERT + ResNet-34</td>
<td>FT</td>
<td>0.8311</td>
<td>0.6277</td>
<td>0.7152</td>
<td>0.8248</td>
</tr>
<tr>
<td>FND-CLIP (BERT and CLIP)</td>
<td>FT</td>
<td>0.6935</td>
<td>0.7151</td>
<td>0.7041</td>
<td>0.8971</td>
</tr>
<tr>
<td>Distill-RoBERTa and CLIP</td>
<td>FT</td>
<td>0.7000</td>
<td>0.6600</td>
<td>0.6794</td>
<td>0.8600</td>
</tr>
<tr>
<td><strong>Large Vision Language Models</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Phi-3-vision-128k-instruct</td>
<td>0-shot</td>
<td>0.7400</td>
<td>0.6700</td>
<td>0.7033</td>
<td>0.7103</td>
</tr>
<tr>
<td>Phi-3-vision-128k-instruct</td>
<td>5-shot</td>
<td>0.7600</td>
<td>0.7200</td>
<td>0.7395</td>
<td>0.7024</td>
</tr>
<tr>
<td>Phi-3-vision-128k-instruct</td>
<td>IFT</td>
<td>0.7800</td>
<td>0.8000</td>
<td>0.7899</td>
<td>0.7200</td>
</tr>
<tr>
<td>LLaVA-1.6</td>
<td>0-shot</td>
<td>0.7531</td>
<td>0.6466</td>
<td>0.6958</td>
<td>0.6500</td>
</tr>
<tr>
<td>LLaVA-1.6</td>
<td>5-shot</td>
<td>0.7102</td>
<td>0.6893</td>
<td>0.6996</td>
<td>0.6338</td>
</tr>
<tr>
<td>Llama-3.2-11B-Vision-Instruct</td>
<td>0-shot</td>
<td>0.6668</td>
<td>0.7233</td>
<td>0.6939</td>
<td>0.7060</td>
</tr>
<tr>
<td>Llama-3.2-11B-Vision-Instruct</td>
<td>5-shot</td>
<td>0.7570</td>
<td>0.7630</td>
<td>0.7600</td>
<td>0.7299</td>
</tr>
<tr>
<td>Llama-3.2-11B-Vision-Instruct</td>
<td>IFT</td>
<td>0.7893</td>
<td>0.8838</td>
<td>0.8060</td>
<td>0.9040</td>
</tr>
</tbody>
</table>
<p><strong>Table 2</strong>: Performance metrics for various small and large language models in text-image configurations. Configuration types: 0-shot = No prior examples used for inference, 5-shot = Five examples provided for context before inference, FT = Fine-tuning, IFT = Instruction Fine-tuning.</p>
<p>This benchmarking offers an insightful overview of how various models, ranging from smaller to large-scale, perform in distinct environments and tasks. The text-based and multimodal benchmarks reflect the strength of these models in handling the complexities of both textual data and combined text-image inputs, providing a useful reference for selecting the appropriate model based on the task requirements.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>